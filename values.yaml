---
# ------------------------------------------------------------------------------
# nifi:
# ------------------------------------------------------------------------------
# images

image:
  repository: apache/nifi
  tag: "1.13.2"
  pullPolicy: IfNotPresent

ca:
  image:
    repository: apache/nifi-toolkit
    tag: "1.13.2"
    pullPolicy: IfNotPresent

registry:
  image:
    repository: apache/nifi-registry
    pullPolicy: IfNotPresent
    tag: "0.8.0"

zookeeper:
  image:
    registry: docker.io
    repository: bitnami/zookeeper
    pullPolicy: IfNotPresent
    tag: 3.7.0-debian-10-r40


# Number of nifi nodes
replicaCount: 1
# predefined server identities, for scaling (hard to be done) its easier to define tls certs for nodes in advance
predefinedNodeIdentitiesCount: 5

securityContext:
  runAsUser: 1000
  fsGroup: 1000

## @param useHostNetwork - boolean - optional
## Bind ports on the hostNetwork. Useful for CNI networking where hostPort might
## not be supported. The ports need to be available on all hosts. It can be
## used for custom metrics instead of a service endpoint.
##
## WARNING: Make sure that hosts using this are properly firewalled otherwise
## metrics and traces are accepted from any host able to connect to this host.
#

sts:
  # Parallel podManagementPolicy for faster bootstrap and teardown. Default is OrderedReady.
  podManagementPolicy: Parallel
  AntiAffinity: soft
  useHostNetwork: null
  hostPort: null
  pod:
    annotations:
      security.alpha.kubernetes.io/sysctls: net.ipv4.ip_local_port_range=10000 65000
      prometheus.io/scrape: "true"
  serviceAccount:
    create: false
    #  name: nifi

## Useful if using any custom secrets
## Pass in some secrets to use (if required)
# secrets:
# - name: myNifiSecret
#   keys:
#     - key1
#     - key2
#   mountPath: /opt/nifi/secret

## Useful if using any custom configmaps
## Pass in some configmaps to use (if required)
  # configmaps:
  # - name: generate_user_cert
  #   keys:
  #     - generate_user.sh
  #   mountPath: /opt/nifi/nifi-current/config-data/certs/generate_user.sh


properties:
  # use externalSecure for when inbound SSL is provided by nginx-ingress or other external mechanism
  externalSecure: false
  isNode: true # set to false if ldap is enabled
  httpPort: 8080 # set to null if ldap is enabled
  httpsPort: 9443 # set to 9443 if ldap is enabled
  webProxyHost: nifi-nifi.apps.oshi43.csas.elostech.cz
  clusterPort: 6007
  clusterSecure: true # set to true if ldap is enabled
  needClientAuth: true
  siteToSite:
    port: 10000
  authorizer: managed-authorizer
  # use properties.safetyValve to pass explicit 'key: value' pairs that overwrite other configuration
  safetyValve:
    #nifi.variable.registry.properties: "${NIFI_HOME}/example1.properties, ${NIFI_HOME}/example2.properties"
    nifi.web.http.network.interface.default: eth0
    # listen to loopback interface so "kubectl port-forward ..." works
    nifi.web.http.network.interface.lo: lo

  ## Include aditional processors
  # customLibPath: "/opt/configuration_resources/custom_lib"

## Include additional libraries in the Nifi containers by using the postStart handler
## ref: https://kubernetes.io/docs/tasks/configure-pod-container/attach-handler-lifecycle-event/
# postStart: /opt/nifi/psql; wget -P /opt/nifi/psql https://jdbc.postgresql.org/download/postgresql-42.2.6.jar

# Nifi User Authentication
auth:
  admin: CN=admin, OU=NIFI
  SSL:
    keystorePasswd: env:PASS
    truststorePasswd: env:PASS
  ldap:
    enabled: false
  oidc:
    enabled: false
    discoveryUrl:
    clientId:
    clientSecret:
    claimIdentifyingUser: email
    ## Request additional scopes, for example profile
    additionalScopes:

# headless service
headless:
  type: ClusterIP
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"

# ui service
service:
  type: ClusterIP
  httpPort: 8080
  httpsPort: 9443
  # nodePort: 30236
  annotations: {}
    # loadBalancerIP:
    ## Load Balancer sources
    ## https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service
    ##
    # loadBalancerSourceRanges:
    # - 10.10.10.0/24
    ## OIDC authentication requires "sticky" session on the LoadBalancer for JWT to work properly...but AWS doesn't like it on creation
    # sessionAffinity: ClientIP
    # sessionAffinityConfig:
    #   clientIP:
  #     timeoutSeconds: 10800

  # Enables additional port/ports to nifi service for internal processors
  processors:
    enabled: false
    ports:
      - name: processor01
        port: 7001
        targetPort: 7001
        #nodePort: 30701
      - name: processor02
        port: 7002
        targetPort: 7002
        #nodePort: 30702

## Configure Ingress based on the documentation here: https://kubernetes.io/docs/concepts/services-networking/ingress/
##
ingress:
  enabled: false
  annotations: {}
  tls: []
  hosts: []
  path: /
  # If you want to change the default path, see this issue https://github.com/cetic/helm-nifi/issues/22

# Amount of memory to give the NiFi java heap
jvmMemory: 1200m

# Separate image for tailing each log separately and checking zookeeper connectivity
sidecar:
  image: busybox
  tag: "1.32.0"

## Enable persistence using Persistent Volume Claims
## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
##
persistence:
  enabled: true
  storageClass: managed-premium
  accessModes:  [ReadWriteOnce]
  nifidata:
    size: 50Gi
  manual: false
  nfs:
    enabled: false
    storageClass: "nfs"
    # full path will be //xxnfsxxx/databaseflow-storage01..02.., need to be created at advance
    pathPrefix: "//xxxnfsxxx/nifidata"
    server: "xxxnfsxxx.file.core.windows.net"
    mountOptions:
      - nolock
## Configure resource requests and limits
## ref: http://kubernetes.io/docs/user-guide/compute-resources/
##
resources:
   limits:
    cpu: 500m
    memory: 1500Mi
   requests:
    cpu: 400m
    memory: 1300Mi

logresources:
  requests:
    cpu: 10m
    memory: 10Mi
  limits:
    cpu: 50m
    memory: 50Mi

nodeSelector: {}

tolerations:
  - effect: NoSchedule
    key: node-role
    value: monitoring
  - effect: NoSchedule
    key: node-role
    value: logging

initContainers: {}
  # foo-init:  # <- will be used as container name
  #   image: "busybox:1.30.1"
  #   imagePullPolicy: "IfNotPresent"
  #   command: ['sh', '-c', 'echo this is an initContainer']
  #   volumeMounts:
  #     - mountPath: /tmp/foo
  #       name: foo

extraVolumeMounts: []

extraVolumes: []

## Extra containers
extraContainers: []

terminationGracePeriodSeconds: 30

## Extra environment variables that will be pass onto deployment pods
env: []

## Extra environment variables from secrets and config maps
envFrom: []

# envFrom:
#   - configMapRef:
#       name: config-name
#   - secretRef:
#       name: mysecret

## Openshift support
## Use the following varables in order to enable Route and Security Context Constraint creation
openshift:
  scc:
    enabled: true
  route:
    enabled: true
    path: /
    host: "nifi-nifi.apps.oshi43.csas.elostech.cz"
    # isolate namespace for pods in namespace and ingress
  networkpolicy:
    enabled: true

# ca server details
# Setting this true would create a nifi-toolkit based ca server
# The ca server will be used to generate self-signed certificates required setting up secured cluster
# ------------------------------------------------------------------------------
# ca
# ------------------------------------------------------------------------------
ca:
  ## If true, enable the nifi-toolkit certificate authority
  enabled: true
  persistence:
    enabled: true
  server: ""
  service:
    port: 9090
  token: sixteenCharacters
  admin:
    cn: admin
  serviceAccount:
    create: false
    #name: nifi-ca
  openshift:
    scc:
      enabled: false

# ------------------------------------------------------------------------------
# Zookeeper:
# ------------------------------------------------------------------------------
zookeeper:
  ## If true, install the Zookeeper chart
  ## ref: https://github.com/bitnami/charts/blob/master/bitnami/zookeeper/values.yaml
  enabled: true
  ## If the Zookeeper Chart is disabled a URL and port are required to connect
  url: ""
  port: 2181
  replicaCount: 3
  resources:
    requests:
      memory: 256Mi
      cpu: 80m
  replicaCount: 1

# ------------------------------------------------------------------------------
# Nifi registry:
# ------------------------------------------------------------------------------
registry:
  ## If true, install the Nifi registry
  replicaCount: 1 # not tested for more replicas
  enabled: true
  url: ""
  # port: 80
  tolerations:
    - effect: NoSchedule
      key: node-role
      value: monitoring
    - effect: NoSchedule
      key: node-role
      value: logging
  openshift:
    route:
      enabled: true
      path: /
      host: "nifi-registry.apps.oshi43.csas.elostech.cz"
  properties:
    externalSecure: false
    webProxyHost: "nifi-registry.apps.oshi43.csas.elostech.cz"
    clusterSecure: true
    httpPort: 18080
    httpsPort: 18443
  service:
    type: ClusterIP
  auth:
    admin: "CN=admin, OU=NIFI"
  resources:
     limits:
       cpu: 100m
       memory: 512Mi
     requests:
       cpu: 100m
       memory: 400Mi

  ## Add values for the nifi-registry here
  ## ref: https://github.com/dysnix/charts/blob/master/nifi-registry/values.yaml

# Configure metrics
metrics:
  prometheus:
    # Enable Prometheus metrics
    enabled: true
    # Port used to expose Prometheus metrics
    port: 9092
    serviceMonitor:
      # Enable deployment of Prometheus Operator ServiceMonitor resource
      enabled: false
      # Additional labels for the ServiceMonitor
      labels: {}

# registry clusersecure/ use tls
global:
  tls:
    caService:
      port: 9090
    token: sixteenCharacters
    admin:
      cn: admin
    enabled: true
    image:
        repository: apache/nifi-toolkit
        tag: "1.13.2"
        pullPolicy: IfNotPresent
